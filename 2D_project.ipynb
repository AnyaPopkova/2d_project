{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "0-UmUxCyjEPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, root_dir, partition, size=40, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.partition = partition\n",
        "\n",
        "        self.img1_path = os.listdir('%s/%s/1/' % (self.root_dir, partition))\n",
        "        self.mask_path = os.listdir('%s/%s/mask/' % (self.root_dir, partition))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img1_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        img1 = Image.open('%s/%s/1/%s' % (self.root_dir, self.partition, self.img1_path[idx]))\n",
        "        mask = np.array(Image.open('%s/%s/mask/%s' % (self.root_dir, self.partition, self.mask_path[idx])))\n",
        "        \n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return img1, mask"
      ],
      "metadata": {
        "id": "qBVrdO5jqAE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, RandomAutocontrast, RandomAdjustSharpness, Normalize, RandomHorizontalFlip, RandomAutocontrast, RandomVerticalFlip\n",
        "\n",
        "transform = transforms.Compose([ToTensor(),\n",
        "                              transforms.Normalize([0.2823, 0.2935, 0.2716],[0.1515, 0.1607, 0.1534])])\n",
        "\n",
        "transform_1 = transforms.Compose([RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5)])"
      ],
      "metadata": {
        "id": "nQQrPf7iq6jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desination_dir = '/content/2d/'\n",
        "batch_size = 32\n",
        "\n",
        "dataset = Dataset(desination_dir, partition='train', transform = transform_1)\n",
        "\n",
        "trainset, valset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)) - int(len(dataset)*0.8)])\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size = batch_size, shuffle = False)\n",
        "val_loader = DataLoader(valset, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "z_GVtIfNrEtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "id": "2Z6Ee5_XrY0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# структура сети \n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, channels = 16):\n",
        "        super(Unet, self).__init__()\n",
        "        self.channels = channels\n",
        "        \n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, self.channels, kernel_size=3, padding = 1), # n=224\n",
        "            nn.ReLU(), # n=222\n",
        "            nn.Conv2d(self.channels, self.channels, kernel_size=3, padding = 1), # n=224\n",
        "            nn.ReLU()) # n=220\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.MaxPool2d((2, 2)), #n=110\n",
        "            nn.Conv2d(self.channels, self.channels * 2, kernel_size=3, padding = 1), # n=112\n",
        "            nn.ReLU(), # n=3\n",
        "            nn.Conv2d(self.channels * 2, self.channels * 2, kernel_size=3, padding = 1), # n=112\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.MaxPool2d((2, 2)), #n=53\n",
        "            nn.Conv2d(self.channels * 2, self.channels * 2 * 2, kernel_size=3, padding = 1), # n=56\n",
        "            nn.ReLU(), # n=3\n",
        "            nn.Conv2d(self.channels * 4, self.channels * 4, kernel_size=3, padding = 1), # n=56\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(self.channels * 4, self.channels * 4, kernel_size = 3, stride = 2, padding = 1, output_padding=1)) #n=50\n",
        "        \n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(self.channels * 6, self.channels * 4, kernel_size=3, padding = 1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.channels * 4, self.channels * 2, kernel_size=3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(self.channels * 2, self.channels * 2, kernel_size = 3, stride = 2, padding = 1, output_padding=1)\n",
        "        )\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(self.channels * 3, self.channels * 2, kernel_size=3, padding = 1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.channels * 2, self.channels, kernel_size=3, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.channels, 1, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"x\", x.shape) #[4, 3, 224, 224]\n",
        "        x1 = self.block1(x) #[4, 64, 224, 224]\n",
        "        #print(\"x1\", x1.shape)\n",
        "        x2 = self.block2(x1) #[4, 128, 112, 112]\n",
        "        #print(\"x2\", x2.shape)\n",
        "        x3 = self.block3(x2) #[4, 256, 112, 112]\n",
        "        #print(\"x3\", x3.shape)\n",
        "        x4 = torch.cat((x2, x3), dim = 1) #[4, 384, 112, 112]\n",
        "        #print(\"x4\",x4.shape)\n",
        "        x5 = self.block4(x4) #[4, 128, 224, 224]\n",
        "        #print(\"x5\", x5.shape)\n",
        "        x6 = torch.cat((x5, x1), dim = 1) #\n",
        "        #print(\"x6\", x6.shape) #[4, 192, 224, 224]\n",
        "        x7 = self.block5(x6)\n",
        "        #print(\"x7\", x7.shape)\n",
        "        return x7 # predicted map"
      ],
      "metadata": {
        "id": "9n_XwBTRjMAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss\n",
        "class Loss(nn.Module):\n",
        "\n",
        "    def __init__(self, epsilon=1e-6):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, predict, target):\n",
        "        predict = predict.flatten(1)\n",
        "        target = target.flatten(1)\n",
        "\n",
        "        loss = torch.sum(torch.abs(torch.sub(predict, target))) + self.epsilon\n",
        "        #print(\"loss\", loss)\n",
        "      \n",
        "        return loss.mean()  # over batch"
      ],
      "metadata": {
        "id": "sNwKQzq5jRgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = Loss()"
      ],
      "metadata": {
        "id": "nSxK4HVWmIUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, epoch=None, masks_in_progress=[]):\n",
        "    ep_loss = 0\n",
        "    model.train()\n",
        "    for img_batch, masks_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(img_batch.to(device))\n",
        "        loss = criterion(output, masks_batch.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ep_loss += loss.item()\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        with torch.no_grad():\n",
        "            img_batch, masks_batch = batch\n",
        "            output = model(img_batch.to(device))\n",
        "            loss = criterion(output, masks_batch.to(device))\n",
        "            val_loss += loss.item()\n",
        "            if i == 0:\n",
        "                masks_in_progress.append(output[0].cpu())\n",
        "\n",
        "    print(\"Epoch {} Train loss {:.2f} Val loss {:.2f}\".format(epoch, ep_loss/len(train_loader), val_loss/len(val_loader)))"
      ],
      "metadata": {
        "id": "dDj4qvChmveD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl943dtSmwS6",
        "outputId": "882815f2-8945-4339-f6f9-fcb528cbc95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Unet().to(device)\n",
        "criterion = Loss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "with torch.no_grad():\n",
        "    masks_in_progress = [model(next(iter(val_loader))[0].to(device))[0].cpu()]"
      ],
      "metadata": {
        "id": "xo87J6pqmyez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    train(model, criterion, optimizer, epoch, masks_in_progress)"
      ],
      "metadata": {
        "id": "SS3LdAkEnJPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "PJ7euUffpCnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}